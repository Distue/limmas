%\VignetteIndexEntry{LIMMAS : Guide (HowTo)}
%\VignetteDepends{gsubfn}
%\VignetteSuggests{}
%\VignetteImports{igraph}
%\VignettePackage{RamiGO}

%documentclass[12pt, a4paper]{article}
%\documentclass[12pt]{article}
\documentclass[a4paper,11pt]{article}
\usepackage[parfill]{parskip} 
\usepackage{amsmath}
\usepackage{times}
\usepackage{hyperref}
\usepackage[numbers]{natbib}
\usepackage[american]{babel}
\usepackage{authblk}
\usepackage{upquote}
%\renewcommand\Authfont{\scshape}
\renewcommand\Affilfont{\itshape\small}
\usepackage{Sweave}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
%\usepackage{tikz}
\usepackage{graphicx}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}
\input{Limmas-concordance}

%------------------------------------------------------------
\title{\Rpackage{LIMMAS}: Linear models for mass spectrometry}
%------------------------------------------------------------
\author[1,2]{Thomas Schwarzl}
\author[1]{Elisa D Arcangelo}
\author[1]{Norma Bargary}
\author[1]{Matthias Malovits}
\author[1]{Desmond G Higgins}
\affil[1]{Systems Biology Ireland, University College Dublin, Conway Institute, Dublin, Ireland}
\affil[2]{European Molecular Biology Laboratory, Meyerhofstrasse 1, Heidelberg, Germany}




\maketitle
\tableofcontents

%------------------------------------------------------------
\section{Introduction}
%------------------------------------------------------------ 

Quantitative mass spectrometry (MS) allows the analysis of quantitative high-throughput proteomics data. For each 
protein analysed, a mass spectrum is generated which allows protein identification and assessment of protein abundance levels. Despite the remarkable power of MS technology, finding quantitative differences among proteins levels in distinct physiological conditions remains a challenging task (Bantscheff et al, 2007). This is especially true for data sets characterised by a high level of missing values, which is a characteristic frequently seen in MS output data sets (Ref). 
Statistical software used for the identification of differentially expressed proteins typically require the data to be complete.
Methods for dealing with missing data are usually inappropriate in that substantial amounts of information is lost and the data distribution is skewed; other, more efficient techniques present themselves as complicated to implement and data set-specific (Ref, http://sites.stat.psu.edu/~jls/mifaq.html). 
Multiple imputation (MI) emerges as an interesting, easy to implement alternative for analysing incomplete data (Ref). 
MI is a Monte Carlo technique which substitutes missing values with m>1 estimated values (m typically amounts to 3-10), thereby producing \emph{m > 1} complete data sets. Each one of these is individually analysed with the statistical method of 
choice and the results are then pooled into estimates, whereby missing-data uncertainty is incorporated (Ref: http://sites.stat.psu.edu/~jls/mifaq.html).
In our approach, we show how incomplete protein entries can be salvaged using MI and the full amount of MS information subsequently used for differential protein expression analysis. Analysis of differential protein expression is  carried out with linear models and empiric Bayes method of the Linear Models for Microarray Data (limma) package (Ref). limma allows to fit a linear model to the expression data of each protein, whereby both simple experiments and 
experimental designs involving several groups and factors as well as time course experiments can be handled effectively.

First we load the library:
\begin{Schunk}
\begin{Sinput}
> library(limmas)
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------
\section{Data input}
%------------------------------------------------------------ 
 
LIMMAS takes an object of class \Robject{ExpressionSet}, here called \emph{eset}, as input. Basically, an \Robject{ExpressionSet} is an object containing expression values as well as the sample annotation (pheno) and feature annotation (protein or peptide information). Those are stored in slots of an \Robject{ExpressionSet}.

The pheno data stored in \emph{eset} can be accessed with \Rfunction{pData(eset)} and should describe the experimental setup. \Rfunction{exprs(eset)} provides the protein intensities, \Rfunction{annotation(eset)} the annotation for the proteins, and \Rfunction{fData(eset)} the meta-information about the quantified proteins.

LIMMAS provides functions to create an object of ExpressionSets from tab-separated files or \Robject{data.frames} from any software for MS quantification. 

Currently, functions for the processing of output files by the popular software \texttt{MaxQuant} are provided. LIMMAS directly reads \emph{proteinGroups.txt} files as input, if the appropriate pheno data is provided manually.

%------------------------------------------------------------
\subsection{Example data}
%------------------------------------------------------------ 
 
To demonstrate our approach, we apply the functions in the LIMMAS package to a label-free quantitative (LFQ) MS data
comparing the protein abundance of immunoprecipitated GEFH1 binding partners. 2 technical and 3 biological 
replicates each of sample groups were generated. The groups are: (1) antibody control, (2) GEFH1, and (3) GEFH1 + Mek 
Inhibitor. These were quantified using \texttt{MaxQuant} software (Ref) and technical replicates were also summed up by 
\texttt{MaxQuant}. Activation of the guanine exchange factor GEFH1 is dependent on the action of Mek (ref). This study aimed at detecting changes in protein binding dependent on the presence of a specific Mek Inhibitor.

The ExpressionSet containing this data can be loaded with
\begin{Schunk}
\begin{Sinput}
> # data(gefh1)
\end{Sinput}
\end{Schunk}

If you want to use the example data, you can continue to \ref{sec:filtering}.

%------------------------------------------------------------
\subsection{Read in \texttt{MaxQuant} data}
%------------------------------------------------------------ 

Firstly, sample information called 'pheno file' specifying the experimental conditions and different factors of the study is needed as \Robject{SmartAnnotatedDataFrame}. This is then used to read in the raw protein intensities from the \texttt{MaxQuant} output \emph{proteinGroups.txt} file. This will provide an \Robject{ExpressionSet} for further analysis.

%------------------------------------------------------------ 
\subsubsection{pheno data}
%------------------------------------------------------------ 

Here we show how to create a pheno file and read in pheno information
as \Robject{SmartAnnotatedDataFrame}.

%------------------------------------------------------------ 
\textbf{Creating a pheno file}
%------------------------------------------------------------ 

A pheno file is a tab-separated text-file where each row describes a sample.
Here, the rows start with the sample name, then the column name of the raw data file
where the protein intensities can be found. The next column 'groups' 
describes the sample groups. Any other 
factors for the analysis can be added, one factor per column.

We call this pheno file ``pheno.txt''.

\begin{verbatim}
                  OrigNames	            groups	    
Control.A	        LFQ.intensity.ALEX_1	 Control	    
Control.B	        LFQ.intensity.ALEX_2	 Control	    
Control.C	        LFQ.intensity.ALEX_3	 Control	    
GEFh1.A           LFQ.intensity.ALEX_4	 Gefh1	    
GEFh1.B           LFQ.intensity.ALEX_5	 Gefh1	    
GEFh1.C           LFQ.intensity.ALEX_6	 Gefh1	    
GEFh1.MEKInhib.A	 LFQ.intensity.ALEX_7	 Gefh1Inhib	 
GEFh1.MEKInhib.B	 LFQ.intensity.ALEX_8	 Gefh1Inhib	 
GEFh1.MEKInhib.C	 LFQ.intensity.ALEX_9	 Gefh1Inhib	 
\end{verbatim}

%------------------------------------------------------------ 
\textbf{Reading from file}
%------------------------------------------------------------ 

The pheno file can be directly read into the workspace by calling

\begin{Schunk}
\begin{Sinput}
> # pheno <- read.pheno("pheno.txt", originalNamesCol="OrigNames", sampleNamesCol="")
\end{Sinput}
\end{Schunk}

When reading in the protein intensity raw data, it is often convenient to re-name the samples. LIMMAS provides this function automatically when given original sample names and new sample names for renaming.

\emph{originalNamesCol} defines the name of the column 
of the pheno data which keeps the raw sample names. This are the exact column names of the data file which hold the protein intensities and are read in in the next step. In the case of the here described data set, this would be for example ``OrigNames''. 

\emph{sampleNamesCol} specifies the name of the column of the pheno data
which keeps the new sample names. ``'' means simply, that the sample names are stored in the 
rownames.

In short, after reading the data file, the name for sample \texttt{LFQ.intensity.ALEX 1} will be \texttt{Control.A} in the resulting \Robject{ExpressionSet}. Should the user want to keep the original sample names, the same value must be specified in both arguments.

\Rfunction{read.pheno} creates pheno data of the class \Robject{SmartAnnotatedDataFrame}.

%------------------------------------------------------------ 
\textbf{Reading from data frame}
%------------------------------------------------------------ 

If the pheno information is already stored in a \Robject{data.frame}, here \emph{pheno.input}, the following command will create the \Robject{SmartAnnotatedDataFrame} object \Robject{pheno}.

\begin{Schunk}
\begin{Sinput}
> #pheno <- SmartAnnotatedDataFrame(pheno.input)
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------ 
\textbf{SmartAnnotatedDataFrame functions}
%------------------------------------------------------------ 

\Robject{SmartAnnotatedDataFrame} is a derived class from 
\Robject{AnnotatedDataFrame} and therefore has all functionalities
of \Robject{AnnotatedDataFrame} objects, as well as additional functions.

An already existing method \Rfunction{pData} displays the raw pheno data

\begin{Schunk}
\begin{Sinput}
> #pData(pheno)
\end{Sinput}
\end{Schunk}

Sometimes samples have to be excluded because of quality issues, or because only a subset of the data set is analysed. In the \Robject{SmartAnnotatedDataFrame} object, factors will automatically re-level when samples are excluded. If for example, in the example data the control was to be excluded,

\begin{Schunk}
\begin{Sinput}
> #pheno.without.control <- pheno[,-c(1:3)]
\end{Sinput}
\end{Schunk}

the factor returned by pData(pheno.without.control)[,``groups''] would contain two, not three levels

\begin{Schunk}
\begin{Sinput}
> #pData(pheno.without.control)[,``groups'']
\end{Sinput}
\end{Schunk}

When successfully created an \Robject{SmartAnnotatedDataFrame} following functions will work:

\Rfunction{getOriginalNames} returns all original sample names.
\begin{Schunk}
\begin{Sinput}
> #getOriginalNames(pheno)
\end{Sinput}
\end{Schunk}

\Rfunction{getSampleNames} returns all new sample names.
\begin{Schunk}
\begin{Sinput}
> #getSampleNames(pheno) 
\end{Sinput}
\end{Schunk}

\Rfunction{getAnnotatedDataFrame} returns an AnnotatedDataFrame without the original sample name column and the new samples as rownames. 
\begin{Schunk}
\begin{Sinput}
> #getAnnotatedDataFrame(pheno))
\end{Sinput}
\end{Schunk}


%------------------------------------------------------------ 
\subsubsection{protein intensity data}
%------------------------------------------------------------ 

Given the \Robject{SmartAnnotatedDataFrame}, \texttt{MaxQuant} intensity data can easily read in.  

%------------------------------------------------------------ 
\textbf{From proteinGroups.txt file}
%------------------------------------------------------------ 

The \texttt{MaxQuant} text output file proteinGroups.txt contains the intensities on protein level and a lot of meta information about the quantification process. \Rfunction{read.maxQuant} takes an \Robject{SmartAnnotatedDataFrame} and reads in the samples specified in the \Robject{SmartAnnotatedDataFrame}. It returns the \Robject{ExpressionSet} object we need for analysis.

\begin{Schunk}
\begin{Sinput}
> #data <- read.maxQuant(file= 'maxQuantFile.txt', pheno, splitIds= ';')
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------ 
\textbf{From data frame}
%------------------------------------------------------------

The function \Rfunction{createExpressionSetFromMaxQuant} processes MaxQuant output and provides an object of the class \Robject{ExpressionSet} as utilised in the package \Rpackage{Biobase} (Ref).
The function splits the data.frame in the tab-separated data file using the original sample name columns from the 
\Robject{SmartAnnotatedDataFrame} object as protein intensities in \Rfunction{exprs(data)}. It assigns the sample names defined in pheno as column name of the intensities. Via the parameter protein annotation is retrieved from the data and stored in \Rfunction{annotation(data)}. The remaining input data is stored in \Rfunction{fData(data)}. This can contain meta-information about peptide 
counts, contaminants, etc. 

In summary, the features of data can be viewed as follows:
\begin{itemize}
   \item \Rfunction{exprs(data)} returns the protein intensity values 
   \item \Rfunction{pData(data)} returns the corresponding pheno data
   \item \Rfunction{annotation(data)} views the protein ids
   \item \Rfunction{fData(data)} views other features included in the raw input experimental data 
\end{itemize}


%------------------------------------------------------------
\subsection{Other sources}
%------------------------------------------------------------ 

For sources different from \texttt{MaxQuant}, \Robject{ExpressionSet} objects can be created easily with the provided function

\begin{Schunk}
\begin{Sinput}
> #data <- createExpressionSet(intensities, pheno, features, annotation)
\end{Sinput}
\end{Schunk}

\begin{itemize}
   \item \Robject{intensities} is an expression matrix of protein intensities.
   \item \Robject{pheno} can be either an \Robject{AnnotatedDataFrame} or \Robject{SmartAnnotatedDataFrame}.      
   \item \Robject{features} is \Robject{matrix} for feature data.
   \item \Robject{annotation} is a \Robject{character} string containing the protein annotation.
\end{itemize}
For manual creation of an \Robject{ExpressionSet}, please refer to the \Robject{ExpressionSet} manual pages.


%------------------------------------------------------------
\section{Filtering}
\label{sec:filtering}
%------------------------------------------------------------

Three filtering steps strip the raw data from unwanted protein entries, including proteins identified on the basis of only one peptide fragment and positive protein hits in reverse- and contaminant databases. This information should be found in \Rfunction{fData(data)}.

%------------------------------------------------------------
\subsection{Peptide Filter}
%------------------------------------------------------------

\Rfunction{peptideFilter} represents the first filtering step. This function removes all protein entries of an object of the class \Robject{ExpressionSet}, which are characterised by a peptide count smaller than or equal to a user-defined cut-off in the column named ``peptides''.

\begin{Schunk}
\begin{Sinput}
> #dim(data)
> #data<-peptideFilter(data)
> #dim(data)
\end{Sinput}
\end{Schunk}

The default value for the parameter \Robject{peptideCutoff} within the function is 1. The amount of protein entries after filtering can easily be checked using \Rfunction{dim(data)}.

%------------------------------------------------------------
\subsection{Reverse Filter}
%------------------------------------------------------------

\Rfunction{reverseFilter} is a function responsible for the removal of all proteins shown to be positive in the reverse peptide database of choice. This is annotated in the data set with e.g. a '+' symbol in the column 'reverse'. Should the original data set contain a different symbol to indicate positive hits, the user is required to change the symbol description with 
the parameter 'symbol' within the function.

\begin{Schunk}
\begin{Sinput}
> #dim(data)
> #data<-reverseFilter(data)
> #dim(data)
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------
\subsection{Contaminant Filter}
%------------------------------------------------------------

Finally, the \Rfunction{contaminantFilter} function removes proteins contained in the chosen contaminant database. The same remark concerning the symbol used to indicate positive hits in the column 'contaminant' is used as above.

\begin{Schunk}
\begin{Sinput}
> #dim(data)
> #data<-contaminantFilter(data)
> #dim(data)
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------
\section{Check missingness}
%------------------------------------------------------------

Of great interest for the user and for the purpose of MI is the degree of missingness across the data set. The percentage of missing data in each sample can be checked using \Rfunction{checkMissingness(data)}:

\begin{Schunk}
\begin{Sinput}
> #checkMissingness(data)
\end{Sinput}
\end{Schunk}

The number of missing value-free rows across samples can also be determined by calling \Rfunction{checkCompleteRows(data)}

\begin{Schunk}
\begin{Sinput}
> #checkCompleteRows(data)
\end{Sinput}
\end{Schunk}


Missing values within a MS data set are the result of random or systematic detection errors. It is therefore often hard to determine, especially for proteins close to the detection limit, whether an entity is truly missing or simply not recorded. 

Knowing how likely any protein entity is missing in a given sample is therefore a useful insight that aids in the decision of pinpointing a threshold for true negative detection. This can be accomplished utilising the function \Rfunction{getMaxProbabilityMissingByChance(data, "groups", 3)}. This command calculates the maximum probability of any number of observed values being missing by chance in all groups of replicates, whereby the argument ‘groups’ determines the column in the pheno file that defines individual groups; the number of missing values can be specified with a number <= number of replicates.

\begin{Schunk}
\begin{Sinput}
> #getMaxProbabilityMissingByChance(data, "groups", 3)
\end{Sinput}
\end{Schunk}

%------------------------------------------------------------
\section{Preprocessing}
%------------------------------------------------------------

Before imputation and statistical testing, the data is subjected to normalization, scaling and transformation.
It has been observed that normalization is best carried out prior to MI (Ref). Normal data distribution 
is necessary for imputation and fitting the linear model in a later step. Quantile normalization is set as the default method. 

\begin{Schunk}
\begin{Sinput}
> #data.normalized <- normalizeData(data, minIntensity=0)
\end{Sinput}
\end{Schunk}

The paramenter minIntensity is arbitrary and allows to set a cut-off for protein intensity values, below which the user deems the observed values to be inaccurate, e.g. due to known irregularities of the mass spectrometer.
Alternative Normalization methods can be used and suggested functions for ExpressionSet objects are described 
in the package affyPLM (Ref) and include:

\begin{itemize}
   \item normalize.ExpressionSet.quantiles
   \item normalize.ExpressionSet.loess
   \item normalize.ExpressionSet.contrasts
   \item normalize.ExpressionSet.qspline
   \item normalize.ExpressionSet.scaling
\end{itemize}

The above functions can be employed by passing them into the \Rfunction{normalizeData} function call with the parameter The function \Rfunction{scaleData} scales down the protein intensity values by dividing them by a user-defined scalefactor argument (here chosen to be 1000).

\begin{Schunk}
\begin{Sinput}
> #data.scaled <- scaleData(data.normalized, 1000)
\end{Sinput}
\end{Schunk}

Normal distribution is achieved via a final step of log-transformation, which is widely used in mass spectrometry data (ref). Other transformations can be passed as functions into the \Rfunction{transformData} function if needed with the parameter xxxx.

\begin{Schunk}
\begin{Sinput}
> #data.transformed <- transformData(data.scaled)
\end{Sinput}
\end{Schunk}

Normality is checked using normal quantile-quantile (Q-Q) plots. A 45 degree diagonal from left bottom to top 
right would mean a perfectly normal distributed sample.

\begin{Schunk}
\begin{Sinput}
> #par(mfrow=c(3,3))
> #for(i in 1:9) {
> #  qqnorm(exprs(data.transformed)[,i], main = paste("Normal Q-Q Plot: ", 
> #  colnames(exprs(data.transformed))[i], sep=""))
> #}
\end{Sinput}
\end{Schunk}


%------------------------------------------------------------
\section{Imputation}
%------------------------------------------------------------

MI of the incomplete data set is carried out utilising the function \Rfunction{imputeIndependentGroupsWithAmelia}. As 
described in the \Rpackage{AmeliaII} package (Ref), this command imputes the missing values present in the data set on the basis of the variation of the experimental values recorded, thereby producing a user defined number (\emph{m > 1}) of 
complete data sets. The default number of imputations is set to \emph{m = 10}. 

\begin{Schunk}
\begin{Sinput}
> #imp <- imputeIndependentGroupsWithAmelia(data.transformed, minTotalPresent=2, groupingCol=”groups”)
\end{Sinput}
\end{Schunk}

\Robject{groupingCol} specifies the sets of replicates (groups) across which imputation is to be carried out, as seen in pheno. Importantly, the parameter \Robject{minTotalPresent} specifies the number of observed values required by the user in each set of replicates (group). The following rationale underlies this step: For any specific protein and for each group, if \emph{number of observed values => minTotalPresent}, then both the present and missing values remain unaltered and can be imputed. If however \emph{number of observed values < minTotalPresent}, all values for that protein in that particular group are replaced by NA values and can therefore not be imputed. This approach aids the imputation of likely true positives while hindering the propagation of likely false positive observations.

In the example data, we decided that of the three replicates in each group at least two were required to contain observed data points, in order for the protein intensity values in that specific group to be imputed. Contrarily, for protein entries where only one value out of three was observed in a group and two were missing, the observed value was regarded as a likely false positive and was replaced by NA, thereby completing a full set of three NAs. These data points cannot be imputed.

At this point the in-build \Rpackage{Amelia II} quality checks can be performed. Below is an example of overdispersed starting values diagnostics, specifically for the imputed data in the control group. This diagnostic tool gives some indication as to how sensitive the imputation process is for any particular data set, by visualising how the first and second (as dims=2) principal component change across m imputations (here \emph{m = 10}). If print to screen (\emph{p2s}) is set to 2, a diagnostic output is created. Please refer to the \Rpackage{Amelia II} package description for further details; however, if all lines in the overdispersed starting value plot converge at the same point, it is reflective of a well behaved likelihood of the data.

\begin{Schunk}
\begin{Sinput}
> #disperse(imp$imputation$Control, m=10,dims=2, p2s=2)
\end{Sinput}
\end{Schunk}

The resulting object \Robject{imp} is a list comprising an object of class MImputedExpressionSets , which is specific to \Rpackage{LIMMAS} and carries the imputed protein expression values, and a list containing further imputation parameters returned by \Rpackage{Amelia}.

\begin{Schunk}
\begin{Sinput}
> #summary(imp)
\end{Sinput}
\end{Schunk}

The former can be extracted from imp with this command:

\begin{Schunk}
\begin{Sinput}
> #data.imputed <- imp[[“data”]]
\end{Sinput}
\end{Schunk}

The features of data.imputed can be explored as follows:

%\begin{itemize}
%   \item \Rfuction{numberImputations(data.imputed)} returns 10, if set to default
%   \item \Rfuction{intensities(data.imputed, 1)} returns imputed values of all %groups for the first round of imputation
%   \item \Rfuction{eset(data.imputed, 1)} shows the expression set data for the %first round of imputation
%   \item \Rfuction{pData(data.imputed)} shows the pheno file
%   \item \Rfuction{annotation(data.imputed)} returns the annotation of the imputed %data set
%   \item \Rfuction{fData(data.imputed)} returns all feature data
%   \item \Rfuction{dim(eset(data.imputed, 1)} shows the dimensions of the data %matrix returned by the first round of imputation 
%\end{itemize}

%6 Bait Control


\end{document}
