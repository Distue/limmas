%\VignetteIndexEntry{LIMMAS : Guide (HowTo)}
%\VignettePackage{limmas}
%\VignetteEngine{knitr::knitr}

% to compile this document
% library('knitr'); rm(list=ls()); knit('limmas.Rnw') 

% to create a pdf use
% library('knitr'); rm(list=ls()); knit2pdf('limmas.Rnw') 

\documentclass[12pt]{article}


\newcommand{\Rpackage{limmas}}{\textit{limmas}}
\newcommand{\lowtilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}


<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy = FALSE,
               dev = "pdf",
               fig.show = "hide",
               fig.width = 4,
               fig.height = 4.5,
               message = FALSE)
@ 

% Inconsolata as terminal font
\IfFileExists{inconsolata.sty}{\usepackage{inconsolata}}{\usepackage{zi4}}  

<<style, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

\begin{document}


<<loadlimmas, echo=FALSE>>=
library("limmas")
@



%------------------------------------------------------------
\title{LIMMAS: Linear models for mass spectrometry}
%------------------------------------------------------------

\author{Schwarzl T$^{1,2*}$, D'Arcangelo E$^{1}$, Bargary N$^{1}$, Malovits M$^{1}$, Higgins DG$^{1}$ \\[1em] \small{$^{1}$\small{Systems Biology Ireland, University College Dublin, Conway Institute, Dublin, Ireland} \\ \small{$^{2}$now: European Molecular Biology Laboratory (EMBL), Meyerhofstrasse 1, Heidelberg, Germany} \\ \small{\texttt{$^*$schwarzl@embl.de}}}}

\begin{document}

\maketitle

\begin{abstract}
   Quantitative mass spectrometry (MS) allows the analysis of quantitative high-throughput proteomics data. For each 
   protein analysed, a mass spectrum is generated which allows protein identification and assessment of protein abundance levels. Despite the remarkable power of MS technology, finding quantitative differences among proteins levels in distinct physiological conditions remains a challenging task (Bantscheff et al, 2007). This is especially true for data sets characterised by a high level of missing values, which is a characteristic frequently seen in MS output data sets (Ref). 
   Statistical software used for the identification of differentially expressed proteins typically require the data to be complete.
   Methods for dealing with missing data are usually inappropriate in that substantial amounts of information is lost and the data distribution is skewed; other, more efficient techniques present themselves as complicated to implement and data set-specific (Ref, http://sites.stat.psu.edu/~jls/mifaq.html). 
   Multiple imputation (MI) emerges as an interesting, easy to implement alternative for analysing incomplete data (Ref). 
   MI is a Monte Carlo technique which substitutes missing values with \emph{m \textgreater  1} estimated values (m typically amounts to 3-10), thereby producing \emph{m \textgreater  1} complete data sets. Each one of these is individually analysed with the statistical method of 
   choice and the results are then pooled into estimates, whereby missing-data uncertainty is incorporated (Ref: http://sites.stat.psu.edu/~jls/mifaq.html).
   In our approach, we show how incomplete protein entries can be salvaged using MI and the full amount of MS information subsequently used for differential protein expression analysis. Analysis of differential protein expression is  carried out with linear models and empiric Bayes method of the Linear Models for Microarray Data (limma) package (Ref). limma allows to fit a linear model to the expression data of each protein, whereby both simple experiments and 
   experimental designs involving several groups and factors as well as time course experiments can be handled effectively.
   \vspace{1em}
   
   \textbf{limmas version:} \Sexpr{packageDescription("limmas")$Version}

     \vspace{1em}
     
     \begin{center}
       \begin{tabular}{ | l | }
         \hline 
         If you use \Rpackage{limmas} in published research, please cite:  \\
         \\
         To be announced 
         \\
         \hline
       \end{tabular}
     \end{center}
   
\end{abstract}



<<options, results="hide", echo=FALSE>>=
options(digits=3, width=80, prompt=" ", continue=" ")
@

\newpage

\tableofcontents

%------------------------------------------------------------
\section{Data input}
%------------------------------------------------------------ 
 
LIMMAS takes an object of class \Robject{ExpressionSet}, here called \emph{eset}, as input. Basically, an \Robject{ExpressionSet} is an object containing expression values as well as the sample annotation (pheno) and feature annotation (protein or peptide information). Those are stored in slots of an \Robject{ExpressionSet}.

The pheno data stored in \emph{eset} can be accessed with \Rfunction{pData(eset)} and should describe the experimental setup. \Rfunction{exprs(eset)} provides the protein intensities, \Rfunction{annotation(eset)} the annotation for the proteins, and \Rfunction{fData(eset)} the meta-information about the quantified proteins.

LIMMAS provides functions to create an object of ExpressionSets from tab-separated files or \Robject{data.frames} from any software for MS quantification. 

Currently, functions for the processing of output files by the popular software \texttt{MaxQuant} are provided. LIMMAS directly reads \emph{proteinGroups.txt} files as input, if the appropriate pheno data is provided manually.

%------------------------------------------------------------
\subsection{Example data}
%------------------------------------------------------------ 
 
To demonstrate our approach, we apply the functions in the LIMMAS package to a label-free quantitative (LFQ) MS data
comparing the protein abundance of immunoprecipitated GEFH1 binding partners. 2 technical and 3 biological 
replicates each of sample groups were generated. The groups are: (1) antibody control, (2) GEFH1, and (3) GEFH1 + Mek 
Inhibitor. These were quantified using \texttt{MaxQuant} software (Ref) and technical replicates were also summed up by 
\texttt{MaxQuant}. Activation of the guanine exchange factor GEFH1 is dependent on the action of Mek (ref). This study aimed at detecting changes in protein binding dependent on the presence of a specific Mek Inhibitor.

The ExpressionSet containing this data can be loaded with

<<loadGefh1example,results="hide">>=
#data(gefh1inhib)
load("~/bioc/limmas/limmas/data/gefh1inhib.rda")
data <- gefh1inhib
pheno <- gefh1inhib.pheno
# pData(pheno)
@

If you want to use the example data, you can continue to \ref{sec:filtering}.

%------------------------------------------------------------
\subsection{Read in \texttt{MaxQuant} data}
%------------------------------------------------------------ 

Firstly, sample information called 'pheno file' specifying the experimental conditions and different factors of the study is needed as \Robject{SmartAnnotatedDataFrame}. This is then used to read in the raw protein intensities from the \texttt{MaxQuant} output \emph{proteinGroups.txt} file. This will provide an \Robject{ExpressionSet} for further analysis.

%------------------------------------------------------------ 
\subsubsection{pheno data}
%------------------------------------------------------------ 

Here we show how to create a pheno file and read in pheno information
as \Robject{SmartAnnotatedDataFrame}.

%------------------------------------------------------------ 
\textbf{Creating a pheno file}
%------------------------------------------------------------ 

A pheno file is a tab-separated text-file where each row describes a sample.
As our beloved biologists often chose variable names, \Rpackage{limmas} contains
the functionality to rename these samples to a bioinformatics-friendly name.

In our example, the rows start with the sample name,
then the column name in the raw data file where the
protein intensities can be found. The next column 'groups' 
describes the sample groups. Any other 
factors for the analysis can be added, one factor per column, 
like batch, time.

We call this pheno file ``pheno.txt''.

\begin{verbatim}
                  OrigNames               groups       batch 
Control.A	        LFQ.intensity.ALEX_1	 Control	    A
Control.B	        LFQ.intensity.ALEX_2	 Control	    B
Control.C	        LFQ.intensity.ALEX_3	 Control	    C
GEFh1.A           LFQ.intensity.ALEX_4	 Gefh1	       A
GEFh1.B           LFQ.intensity.ALEX_5	 Gefh1	       B
GEFh1.C           LFQ.intensity.ALEX_6	 Gefh1	       C
GEFh1.MEKInhib.A	 LFQ.intensity.ALEX_7	 Gefh1Inhib	 A
GEFh1.MEKInhib.B	 LFQ.intensity.ALEX_8	 Gefh1Inhib	 B
GEFh1.MEKInhib.C	 LFQ.intensity.ALEX_9	 Gefh1Inhib	 C
\end{verbatim}

%------------------------------------------------------------ 
\textbf{Reading from a file}
%------------------------------------------------------------ 

Your pheno file can be directly read into the workspace by calling

<<readPhenoFile, eval=FALSE>>=
pheno <- read.pheno("pheno.txt", originalNamesCol="OrigNames", sampleNamesCol="")
@

When reading in the protein intensity raw data, it is often convenient to re-name the samples. LIMMAS provides this function automatically when given original sample names and new sample names for renaming.

\emph{originalNamesCol} defines the name of the column 
of the pheno data which keeps the raw sample names. This are the exact column names of the data file which hold the protein intensities and are read in in the next step. In the case of the here described data set, this would be for example ``OrigNames''. 

\emph{sampleNamesCol} specifies the name of the column of the pheno data
which keeps the new sample names. Empty quotes, `` '',  simply means, that the sample names are stored in the 
rownames.

In short, after reading the data file, the name for sample \texttt{LFQ.intensity.ALEX\_1} will be \texttt{Control.A} in the resulting \Robject{ExpressionSet}. Should the user want to keep the original sample names, the same value must be specified in both arguments.

\Rfunction{read.pheno} creates pheno data of the class \Robject{SmartAnnotatedDataFrame}.

%------------------------------------------------------------ 
\textbf{Reading from data frame}
%------------------------------------------------------------ 

If the pheno information is already stored in a \Robject{data.frame}, here \emph{pheno.input}, the following command will create the \Robject{SmartAnnotatedDataFrame} object \Robject{pheno}.

<<phenoFromDataFrame, eval=FALSE>>=
pheno <- SmartAnnotatedDataFrame(pheno.input)
@

%------------------------------------------------------------ 
\textbf{SmartAnnotatedDataFrame functions}
%------------------------------------------------------------ 

\Robject{SmartAnnotatedDataFrame} is a derived class from 
\Robject{AnnotatedDataFrame} and therefore has all functionalities
of \Robject{AnnotatedDataFrame} objects, as well as additional functions.

An already existing method \Rfunction{pData} displays the raw pheno data

<<pDataPheno>>=
pData(pheno)
@

Sometimes samples have to be excluded because of quality issues, or because only a subset of the data set is analysed. In the \Robject{SmartAnnotatedDataFrame} object, factors will automatically re-level when samples are excluded. If for example, in the example data the control was to be excluded,

<<pDataPheno2, eval=FALSE>>=
#BUGGY
pheno.without.control <- pheno[,-c(1:3)]
@

the factor returned by pData(pheno.without.control)[,``groups''] would contain two, not three levels

<<phenoWithOutControl, eval=FALSE>>=
#BUGGY
pData(pheno.without.control)[,``groups'']
@

When successfully created an \Robject{SmartAnnotatedDataFrame} following functions will work:

\Rfunction{getOriginalNames} returns all original sample names.
<<getOriginalNames>>=
getOriginalNames(pheno)
@

\Rfunction{getSampleNames} returns all new sample names.
<<getSampleNames>>=
getSampleNames(pheno) 
@

\Rfunction{getAnnotatedDataFrame} returns an AnnotatedDataFrame without the original sample name column and the new samples as rownames. 
<<getSampleNames2>>=
class(getAnnotatedDataFrame(pheno))
@


%------------------------------------------------------------ 
\subsubsection{Protein intensity data}
%------------------------------------------------------------ 

When the \Robject{SmartAnnotatedDataFrame} is provided, the input of \texttt{MaxQuant} intensity data is very easy.

%------------------------------------------------------------ 
\textbf{From proteinGroups.txt file}
%------------------------------------------------------------ 

The \texttt{MaxQuant} text output file proteinGroups.txt contains the intensities on protein level and a lot of meta information about the quantification process. \Rfunction{read.maxQuant} takes an \Robject{SmartAnnotatedDataFrame} and reads in the samples specified in the \Robject{SmartAnnotatedDataFrame}. It returns the \Robject{ExpressionSet} object we need for analysis.

<<createExpressionSetFromFile, eval=FALSE>>=
data <- read.maxQuant(file = 'proteinGroups.txt', pheno, splitIds = ';')
@

%------------------------------------------------------------ 
\textbf{From data frame}
%------------------------------------------------------------

The function \Rfunction{createExpressionSetFromMaxQuant} processes MaxQuant output and provides an object of the class \Robject{ExpressionSet} as utilised in the package \Rpackage{Biobase} (Ref).
The function splits the data.frame in the tab-separated data file using the original sample name columns from the 
\Robject{SmartAnnotatedDataFrame} object as protein intensities in \Rfunction{exprs(data)}. It assigns the sample names defined in pheno as column name of the intensities. Via the parameter protein annotation is retrieved from the data and stored in \Rfunction{annotation(data)}. The remaining input data is stored in \Rfunction{fData(data)}. This can contain meta-information about peptide 
counts, contaminants, etc. 

In summary, the features of data can be viewed as follows:
\begin{itemize}
   \item \Rfunction{exprs(data)} returns the protein intensity values 
   \item \Rfunction{pData(data)} returns the corresponding pheno data
   \item \Rfunction{annotation(data)} views the protein ids
   \item \Rfunction{fData(data)} views other features included in the raw input experimental data 
\end{itemize}


%------------------------------------------------------------
\subsection{Other sources}
%------------------------------------------------------------ 

For sources different from \texttt{MaxQuant}, \Robject{ExpressionSet} objects can be created easily with the provided function

<<createExpressionSetFromOtherSources, eval=FALSE>>=
data <- createExpressionSet(intensities, pheno, features, annotation)
@

\begin{itemize}
   \item \Robject{intensities} is an expression matrix of protein intensities.
   \item \Robject{pheno} can be either an \Robject{AnnotatedDataFrame} or \Robject{SmartAnnotatedDataFrame}.      
   \item \Robject{features} is \Robject{matrix} for feature data.
   \item \Robject{annotation} is a \Robject{character} string containing the protein annotation.
\end{itemize}
For manual creation of an \Robject{ExpressionSet}, please refer to the \Robject{ExpressionSet} manual pages.


%------------------------------------------------------------
\section{Filtering}
\label{sec:filtering}
%------------------------------------------------------------

Three filtering steps strip the raw data from unwanted protein entries, including proteins identified on the basis of only one peptide fragment and positive protein hits in reverse- and contaminant databases. This information should be found in \Rfunction{fData(data)}.

%------------------------------------------------------------
\subsection{Peptide Filter}
%------------------------------------------------------------

\Rfunction{peptideFilter} represents the first filtering step. This function removes all protein entries of an object of the class \Robject{ExpressionSet}, which are characterised by a peptide count smaller than or equal to a user-defined cut-off in the column named ``peptides''. This column contains the maximum amount of peptides for given proteins found in any sample. \Robject{peptideColumns} specifies in which columns the peptide information is stored, that can be a single or multiple columns. \Robject{method} defines if the peptide count has to '''greater''' the
\Robject{peptideCutoff} in '''all''' or in '''any''' of the columns specified in \Robject{peptideColumns}.


<<peptideFilter>>=
nrow(data)
data <- peptideFilter(data, peptideCutoff=1, peptideColumns=c("Peptides"), method="any")
nrow(data)
@

The default value for the parameter \Robject{peptideCutoff} within the function is 1. The amount of protein entries after filtering can easily be checked using \Rfunction{nrow(data)}.

%------------------------------------------------------------
\subsection{Reverse Filter}
%------------------------------------------------------------

\Rfunction{reverseFilter} is a function responsible for the removal of all proteins shown to be positive in the reverse peptide database of choice. This is annotated in the data set with e.g. a '+' symbol in the column 'reverse'. Should the original data set contain a different symbol to indicate positive hits, the user is required to change the symbol description with 
the parameter 'symbol' within the function.

<<reverseFilter>>=
nrow(data)
data <- reverseFilter(data, symbol = "+", reverseColumn="Reverse")
nrow(data)
@

%------------------------------------------------------------
\subsection{Contaminant Filter}
%------------------------------------------------------------

Finally, the \Rfunction{contaminantFilter} function removes proteins contained in the chosen contaminant database. The same remark concerning the symbol used to indicate positive hits in the column 'contaminant' is used as above.

<<contaminentFilter>>=
nrow(data)
data <- contaminantFilter(data, symbol = "+", contaminantColumn="Contaminant")
nrow(data)
@

%------------------------------------------------------------
\section{QC before preprocessing}
%------------------------------------------------------------

%------------------------------------------------------------
\subsection{Correlation}
%------------------------------------------------------------
Correlations between samples can easily be calculated 
using \Rfunction{calculateFeatureCorrelations}.

<<correlationBeforeQC>>=
calculateFeatureCorrelations(data)
@

%------------------------------------------------------------
\subsection{Histogram}
%------------------------------------------------------------

With \Rfunction{hist} we can create a histogram of the 
non-missing values before the 
normalization (Figure \ref{figure/histBeforeQC}).

<<histBeforeQC, fig.width=6, fig.height=6, results='hide'>>=
hist(data)
@

\incfig{figure/histBeforeQC}{0.6\textwidth}{Histogram before QC}{
}


%------------------------------------------------------------
\subsection{Boxplot}
%------------------------------------------------------------

\Rfunction{boxplotBeforeQC} will create a barchart for our data
set before the preprossing (Figure \ref{figure/boxplotBeforeQC}).

<<boxplotBeforeQC, fig.width=6, fig.height=6, results='hide'>>=
boxplot(data)
@

\incfig{figure/boxplotBeforeQC}{0.6\textwidth}{Barchart before QC}{
}

%------------------------------------------------------------
\subsection{Complete Rows}
%------------------------------------------------------------

Of great interest for the user and for the purpose of MI is the degree of completeness of the data set. The number of missing value-free rows across samples can  be determined by calling\\ \Rfunction{checkCompleteRows(data)}

<<checkCompleteRows>>=
before.imputation <- checkCompleteRows(data)
before.imputation 
@

In contrary, the median missingness across the data set provides a crude overview of missing data in each sample. This can be checked with \Rfunction{checkMissingness(data)}:

<<checkMissingness>>=
checkMissingness(data)
@

A better overview is provided using the visual representation of missingness will be later used in \ref{sec:Detection limit}. Before this, we will preprocess the data.

%------------------------------------------------------------
\section{Preprocessing}
%------------------------------------------------------------

Before imputation and statistical testing, the data is subjected to normalization, scaling and transformation.
It has been observed that normalization is best carried out prior to MI (Ref). Normal data distribution 
is necessary for imputation and fitting the linear model in a later step. Quantile normalization is set as the default method. 

<<normalizeData>>=
data.normalized <- normalizeData(data,
                                 minIntensity = 0,
                                 FUN = normalize.ExpressionSet.quantiles) 
@

The paramenter minIntensity is arbitrary and allows to set a cut-off for protein intensity values, below which the user deems the observed values to be inaccurate, e.g. due to known irregularities of the mass spectrometer.
Alternative Normalization methods can be used and suggested functions for ExpressionSet objects are described 
in the package \Rpackage{affyPLM} and include:

\begin{itemize}
   \item normalize.ExpressionSet.quantiles
   \item normalize.ExpressionSet.loess
   \item normalize.ExpressionSet.contrasts
   \item normalize.ExpressionSet.qspline
   \item normalize.ExpressionSet.scaling
\end{itemize}

The above functions can be employed by passing them into the \Rfunction{normalizeData} function call with the parameter. Remember that you can use the full functionality of an \Rclass{ExpressionSet} object, e.g. you can plot histograms and boxplots easily with
 
<<hist, eval=FALSE>>=
hist(data.transformed) 
boxplot(data.transformed)
@

of the normalized data as well as the transformed but not normalized data:

<<histWithoutNormalization, eval=FALSE>>=
hist(transformData(data))
boxplot(transformData(data))
@

Eventually, you want to subset the data to normalize the controls and samples 
separately. The use of \Rclass{ExpressionSet} in \Rpackage{limmas} provides a very flexible
data structure to adapt to different data set properties.

The function \Rfunction{scaleData} scales down the protein intensity values by dividing them by a user-defined scalefactor argument (here chosen to be 1000).

<<scaleData>>=
data.scaled <- scaleData(data.normalized, 1000)
@

Normal distribution usually is achieved via a final step of log-transformation, which is widely used in mass spectrometry data. 

<<transformData>>=
data.transformed <- transformData(data.scaled)
@

Other transformations can be passed as functions into the \Rfunction{transformData} function if needed with the parameter FUN. Here is the example how the log transformation is passed on. In short, this function will be simply applied to the ExpressionSet.

<<transformDataExtended, eval=FALSE>>=
data.transformed <- transformData(data.scaled,
                                  FUN = function(x) {
                                           exprs(x) <- log(exprs(x));
                                           return(x)
                                   })
@

%------------------------------------------------------------
\section{QC after preprocessing}
%------------------------------------------------------------

%------------------------------------------------------------
\subsection{Normality}
%------------------------------------------------------------

Normality is checked using normal quantile-quantile (Q-Q) plots. A 45 degree diagonal from left bottom to top 
right would mean a perfectly normal distributed sample as shown in Figure \ref{figure/qqnorm}.
Alternatively, a Shapiro-Wilk test could be performed.


<<qqnorm, fig.width=6, fig.height=7>>=
par(mfrow=c(3,3), oma=c(3,3,3,3))
for(i in 1:9) {
   qqnorm(exprs(data.transformed)[,i],
          main = paste("Normal Q-Q Plot: ", 
          colnames(exprs(data.transformed))[i], sep = ""),
          cex=0.8,
          cex.main=0.7)
}
@



\incfig{figure/qqnorm}{\textwidth}{QQplots of all samples}{
}


%------------------------------------------------------------
\subsection{Correlation}
%------------------------------------------------------------
Correlations between samples can easily be calculated 
using \Rfunction{calculateFeatureCorrelations}.

<<correlationAfterQC>>=
calculateFeatureCorrelations(data)
@

%------------------------------------------------------------
\subsection{Histogram}
%------------------------------------------------------------

With \Rfunction{hist} we can create a histogram after the 
normalization (Figure \ref{figure/histAfterQC}).

<<histAfterQC, fig.width=6, fig.height=6, results='hide'>>=
hist(data)
@

\incfig{figure/histAfterQC}{0.6\textwidth}{Histogram after QC}{
}


%------------------------------------------------------------
\subsection{Boxplot}
%------------------------------------------------------------

\Rfunction{boxplotAfterQC} will create a barchart for our data
set after the preprossing (Figure \ref{figure/boxplotAfterQC}).

<<boxplotAfterQC, fig.width=6, fig.height=6, results='hide'>>=
boxplot(data)
@

\incfig{figure/boxplotAfterQC}{0.6\textwidth}{Barchart after QC}{
}

%------------------------------------------------------------
\section{Detection limit}
%------------------------------------------------------------

Missing values within a MS data set are the result of random or systematic
detection errors. It is therefore often hard to determine, especially for
proteins close to the detection limit, whether an entity is truly missing
or simply not recorded. 

Knowing how likely any protein entity is missing in a given sample is
therefore a useful insight that aids in the decision of pinpointing a
threshold for true negative detection. 

Replicates can be used to determine missing values introduced by random errors. 
Those can be filled up statistically with imputation methods. Then we are
left with missing values due to the left cencoring caused by the detection limit.

But that is okay, because biologically, we often want to know if the protein 
is \emph{higher} abundant than the not detected protein. Therefore we estimate
the percentage of non-detection with following method.

<<NAhist, fig.width=5, fig.height=5>>=
par(mfrow=c(2,2))
lapply(levels(pData(data.transformed)[,"groups"]), function (x) { 
   plotNAdensity(data.transformed, group = x, groupCol = "groups")
})  
@

\incfig{figure/NAhist}{\textwidth}{Histograms of missing value occurances.}{
}


This can be accomplished utilising
the function \Rfunction{getMaxProbabilityMissingByChance(data, "groups", 3)}.
This command calculates the maximum probability of any number of observed
values being missing by chance in all groups of replicates, whereby the argument ‘groups’ determines the column in the pheno file that defines individual groups; the number of missing values can be specified with a number \geq number of replicates.

<<getMaxProbabilityMissingByChance>>=
#TODO
# getMaxProbabilityMissingByChance(data, "groups", 3)
@

%------------------------------------------------------------
\section{Multiple Imputation}
%------------------------------------------------------------

Multiple Imputation (MI) is a statistical method to fill up missing data {Ref}.
Compared to other imputation methods, it has the advantage that the imputated
values (statistically generated filled in gaps) reflect the variance of the 
real data set {Ref}. This is in particular important for high-throughput 
experiments with replicates.

\Rpackage{limmas} uses the \Rpackage{Amelia II} R package for the multiple imputation,
however it can be substituted for any multiple imputation algorithm can be used.
The input is an \Rclass{ExpressionSet} object and the output is an
\Rclass{MImputedExpressionSet} object. The \Rclass{MImputedExpressionSet} object
contains a list of imputed data sets (\Rclass{ExpressionSet}s with filled up
values), as well as the original data.

%------------------------------------------------------------
\subsection{Amelia II - Independent Groups}
%------------------------------------------------------------
In a immunoprecipitation setup with quantitative label-free MS,
protein binding partners of a specific target are investigated.
In different conditions, a protein might have a strong binding
affinity, whereas in other conditions a protein does not bind
at all. 

We observed, that MI algorithms tend to fill up values for 
features in a condition with no observerations at all. This 
independent group approach was developed to firstly take 
replicate information for filling up missing values and 
secondly leave empty observations untouched for biological
interpretation.

MI of the incomplete data set is carried out utilising the
function \Rfunction{imputeIndependentGroupsWithAmelia}. As 
described in the \Rpackage{AmeliaII} package (Ref), this
command imputes the missing values present in the data set
on the basis of the variation of the experimental values
recorded, thereby producing a user defined number
(\emph{m \textgreater 1}) of complete data sets. The default number
of imputations is set to \emph{m = 10}. 

<<imputeIndependentGroupsWithAmelia, warning=FALSE, results='hide'>>=
impResult <- imputeIndependentGroupsWithAmelia(data.transformed,
                                         minTotalPresent = 2,
                                         groupingCol = "groups")

@


\Robject{groupingCol} specifies the sets of replicates (groups)
across which imputation is to be carried out, as seen in pheno.
Importantly, the parameter \Robject{minTotalPresent} specifies
the number of observed values required by the user in each set
of replicates (group). The following rationale underlies this
step: For any specific protein and for each group, if \emph{number
of observed values \textgreater=  minTotalPresent }, then both the present
and missing values remain unaltered and can be imputed. If however
\emph{number of observed values < minTotalPresent}, all values for
that protein in that particular group are replaced by NA values 
and can therefore not be imputed. This approach aids the imputation
of likely true positives while hindering the propagation of likely 
false positive observations.

\emph{Note: \Rpackage{Amelia II} will raise 
a warning 'There are observations in the data that are completely 
missing. These observations will remain unimputed in the final 
datasets.' which is exactly what we want.}

In the example data, we decided that of the three replicates in 
each group at least two were required to contain observed data points, 
in order for the protein intensity values in that specific group to 
be imputed. Contrarily, for protein entries where only one value out
of three was observed in a group and two were missing, the observed 
value was regarded as a likely false positive and was replaced by NA,
thereby completing a full set of three NAs. These data points cannot
be imputed.

The resulting object \Robject{impResult} is a list comprising an object of class MImputedExpressionSets , which is specific to \Rpackage{LIMMAS} and carries the imputed protein expression values, and a list containing further imputation parameters returned by \Rpackage{Amelia}.

<<ameliaQC2>>=
summary(impResult)
@

At this point the in-build \Rpackage{Amelia II} quality checks 
can be performed. Below is an example of overdispersed starting 
values diagnostics, specifically for the imputed data in the control
group. This diagnostic tool gives some indication as to how sensitive 
the imputation process is for any particular data set, by visualising
how the first and second (as dims=2) principal component change 
across m imputations (here \emph{m = 10}). If print to screen 
(\emph{p2s}) is set to 2, a diagnostic output is created. Please 
refer to the \Rpackage{Amelia II} package description for further 
details; however, if all lines in the overdispersed starting value
plot converge at the same point, it is reflective of a well behaved
likelihood of the data as seen in Figure \ref{figure/ameliaQC}.

<<ameliaQC, fig.width=6, fig.height=7, results='hide', warning=FALSE>>=
disperse(impResult[["imputation"]]$Control, m = 10, dims = 2, p2s = 2)
@


\incfig{figure/ameliaQC}{0.6\textwidth}{Overdispersed starting values}{
}

The \Rclass{MImputedExpressionSet} can be extracted from
\Robject{impResult} with this command:

<<getImputedData>>=
data.imputed <- impResult[["data"]]
@

The features of the \Rclass{MImputedExpressionSet} in data.imputed
can be explored as follows:

- Number of Imputations (returns 10, if set to default)
<<ImputedFeatures, eval=FALSE>>=
   numberImputations(data.imputed)}
@

- Imputed values of all groups for the first round of imputation
<<ImputedFeaturesIntensities, eval=FALSE>>=
   intensities(data.imputed, 1)
@

- Shows the expression set data for the first round of imputation:
<<ImputedFeaturesEset, eval=FALSE>>=
   eset(data.imputed, 1)
@

- Shows the pheno file
<<ImputedFeaturespData, eval=FALSE>>=
   pData(data.imputed)
@

- Annotation of the imputed data set
<<ImputedFeaturesAnnotation, eval=FALSE>>=
   annotation(data.imputed)
@

- All feature data
<<ImputedFeaturesfData, eval=FALSE>>=
   fData(data.imputed)
@

- Dimensions of the data matrix returned by the first round of imputation 
<<ImputedFeaturesDim, eval=FALSE>>=
   dim(eset(data.imputed, 1))
@

\subsection{Amelia II - no groups} 

\Rpackage{limmas}  will be extended in the future to include other imputation methods 
and variants. If you want to impute over the whole data set without 
group associations, then just insert the same value for all samples in the 
group column in the \emph{pheno} file and run Amelia II - Independent groups - 
as explained above.

\subsection{Other imputation methods} 
As mentioned, custom imputation algorithms can be used. Just transform the 
\emph{m} imputed data sets into \Rclass{ExpressionSets} and create an 
\Rclass{MImputedExpressionSet}.


After the successful imputation, the analysis will be performed.

\section{Before analysis}

\subsection{Bait Control}
In immunoprecipitation setups, you want to check for the protein of interest. 
Usually, anti-body controls are performed to control for unspecific binding.
The easiest way to quickly assess the levels of the protein is to plot the
protein intensities in the MS data (Figure \ref{figure/bait}).

<<bait, fig.width=6, fig.height=6, results='hide', warning=FALSE>>=
par(oma=c(4,4,4,4))
plotExpression(data.imputed, "Q92974")
@

\incfig{figure/bait}{0.8\textwidth}{Bait control plot}{
Here, clearly you can see that the control was detected in all of the samples
and the control and has a much higher expression than the control in both 
conditions.
}

\subsection{Complete Cases} 
There are applications where you want to compare only complete feature rows in
your data set, or if you want to assess how many rows got completely filled 
up by the imputation. The complete feature rows can be extracted by:

<<complete>>=
data.complete <- completeCases(data.imputed)
@ 

and the row count can be checked by
<<nrowComplete>>=
after.imputation <- nrow(eset(data.complete, 1))
after.imputation
@


\subsection{Filling up the missing values} 

Biologically, the most interesting cases are proteins which are detected
in one condition and are significantly not detectable in the other condition.

Therefore we can just fill the missing values with 0s. \emph{Note: This
approach has to be complemented by other analysis and the interpretation 
has to be adjusted. A logFC between a 0 value condition and a real value
condition cannot be taken a statistical value, but merely it allows to
easily filter out and interepret the e.g. \textgreater 10 logFC. Also the linear 
model can vary when the model is built on this filled data set. Therefore
always do a compelete case analysis as well.} However, this approach is a
very quick and convient way to analyse and assess the whole data once the
biological interpretation is clear.

<<fillNAs>>=
data.filled <- fillNAsWithValues(data.imputed, 0) 
nrow(eset(data.filled, 1))  
@

\section{Analysis}
For the statistical analysis, \Rpackage{limmas}  makes use of the fantastic
linear models for microarray (\Rpackage{limma}) package. The 
analysis of MS data is very similar to microarray analysis, 
except the problem with the missing values in MS data. We cope 
with this issue using the multiple imputation approach. \Rpackage{limma}
is extremely flexible, if you have no experience with \Rpackage{limma},
please go and have a look at their extremely well documented vignette. 

\Rpackage{limmas}  uses linear models to do the statistical analysis on the 
\emph{m} different imputed data sets. Linear models can be used 
for multifactorial designs which become more popular with the 
current developments in the MS field. Also, e.g. batch effects 
can be modeled in in the statistical analysis.

After using linear models on the \emph{m} imputed data sets, the 
results have to be statistically \emph{pooled}. This is important 
to adjust for in-between and across data set variablity.
In \Rpackage{limmas}, we included this functionality for 
easy pooling of the results.

\subsection{The design matrix}
A design matrix has to be constructed for fitting the model. This
basic concept is well documented in the \Rpackage{limma} vignette.
Here an example is giving where the model is fitted on group and
batches.

<<designMatrix>>=
p      <- pData(data.imputed)
design <- model.matrix(~0 + p$groups + p$batch, data=p) 
colnames(design) <- c(levels(p$groups), levels(p$batch)[-1])
@

\subsection{Statistics for the complete data set} 
Now we fit the model for each imputed data set, pool the results, do 
the significance testing, multiple hypothesis testing correction,
and display the top results from the first contrast - Gefh1 versus Control.
in \Rpackage{limma} fashion.

<<fitting, warning=FALSE>>=

fit <- limmasFit(data.complete, design)
contrasts <- c("Gefh1 - Control",
               "Gefh1Inhib - Control", 
               "Gefh1Inhib - Gefh1")
fit <- combineFits(contrastFit(fit, contrasts))
topTableImpute(fit, n=5, coef=1) 
@

<<estimation, eval=FALSE>>=

fit <- limmasFit(data.imputed, design)
contrasts <- c("Gefh1 - Control",
               "Gefh1Inhib - Control", 
               "Gefh1Inhib - Gefh1")
fit <- combineFits(contrastFit(fit, contrasts))

fit <- estimateLimits(data.complete, design, contrasts)

@ 

\emph{Note: If you have filled in values for NAs, \Rpackage{limma} can return a
warning, which is expected.}

To retrieve the significant results for all different contrasts:  

<<significantFeatures, warning=FALSE>>=
res.complete <- list()
res.complete[["gefh1"]]         <- getSignificantFeatures(fit, coef=1, p.value=0.05)
res.complete[["gefh1inhib"]]    <- getSignificantFeatures(fit, coef=2, p.value=0.05)
res.complete[["inhib.vs.gefh1"]]<- getSignificantFeatures(fit, coef=3, p.value=0.05)

lapply(res.complete, nrow)
@

Since we have control samples, we want to filter, the results for significantly
higher expression and \textgreater 0.5 logFC in samples versus controls.

<<featureFilter, warning=FALSE>>=
res.complete.filter <- unique(unlist(lapply(c("gefh1", "gefh1inhib"), function(x) {
   rownames(res.complete[[x]][res.complete[[x]][,"logFC"] > 0.5,])
})))

sig.complete <- res.complete[["inhib.vs.gefh1"]][
                       rownames(res.complete[["inhib.vs.gefh1"]]) 
                                                    %in% res.complete.filter,]
nrow(sig.complete)
head(sig.complete)
@

Four proteins are significantly expressed between the two conditions
as well as compared to the control in the complete data set. We plot 
the top result (Figure \ref{figure/completeTop}).

<<completeTop, fig.width=6, fig.height=6, results='hide', warning=FALSE>>=
par(oma=c(4,4,4,4))
plotExpression(data.complete, as.numeric(rownames(sig.complete[1,])))
@

\incfig{figure/completeTop}{0.8\textwidth}{Top expressed in the complete data set}{
}


When a sample contains multiple data points, this means it was imputed.
Then it did not have any values but it was filled up by the 
multiple imputation m times. Other samples with only one data point have
real values.

\subsection{Statistics for the filled data set} 

The same analysis can be performed with the filled data set, however
it is important to be sure of the interpretation of the results. 
<<fittingFilled, warning=FALSE>>=
fit <- limmasFit(data.filled, design)
fit <- combineFits(contrastFit(fit, c("Gefh1 - Control",
                                      "Gefh1Inhib - Control", 
                                      "Gefh1Inhib - Gefh1")))
res.filled <- list()
res.filled[["gefh1"]]         <- getSignificantFeatures(fit, coef=1, p.value=0.05)
res.filled[["gefh1inhib"]]    <- getSignificantFeatures(fit, coef=2, p.value=0.05)
res.filled[["inhib.vs.gefh1"]]<- getSignificantFeatures(fit, coef=3, p.value=0.05)

lapply(res.filled, nrow)
@
\emph{Note: If you have filled in values for NAs, \Rpackage{limma} can return a
Warning, which is expected.}

As above, we filter the results upregulation compared to the control

<<featureFilterFilled, warning=FALSE>>=
res.filled.filter <- unique(unlist(lapply(c("gefh1", "gefh1inhib"), function(x) {
   rownames(res.filled[[x]][res.filled[[x]][,"logFC"] > 0.5,])
})))

sig.filled <- res.filled[["inhib.vs.gefh1"]][
             rownames(res.filled[["inhib.vs.gefh1"]]) %in% res.filled.filter,]

nrow(sig.filled)
head(sig.filled, n=5)
@

This time we get 41 proteins significantly expressed between the groups. 
Now we plot the top result. In Figure \ref{figure/filledTop} it is nicely shown
that the protein is abundant in one condition and not abundant in 
the control or inhibitor condition at all. \emph{Note: In reality, the samples
with intensities of zero are under the detection limit and not necessarily
zero!}

<<filledTop, fig.width=6, fig.height=6, results='hide', warning=FALSE>>=
par(oma=c(4,4,4,4))
plotExpression(data.filled, as.numeric(rownames(sig.filled[1,])))
@

\incfig{figure/filledTop}{0.8\textwidth}{Top expressed in filled data set }{
}

To sum this up, if the features have values for each sample (are complete), 
then you want to use the model fit of the complete data set, as the 
filled in model gives an approximation. However, it is extremely useful 
to filter for genes which are up in one condition and for example
under the detection limit in the other condition.

Now it is time for some remaining stats on the data set.

Amount of complete rows before the imputation
<<beforeImp>>= 
before.imputation 
@

Amount of complete rows after the imputation
<<afterImp>>= 
after.imputation 
@

The biggest differences in the gefh1 and the gefh1 inhibitor are detected by
looking at the data set with filled values. With our approach we 
can estimate that those are most likely not missing by chance and 
biologically might be most important. 

<<stats>>=
stats <- t(data.frame(sapply(c("gefh1", "gefh1inhib", "inhib.vs.gefh1"), function(x) {
    return(c(nrow(res.complete[[x]]),
             nrow(res.filled[[x]]),
             nrow(res.filled[[x]])/nrow(res.complete[[x]]),
             sum(rownames(res.filled[[x]]) %in% rownames(res.complete[[x]])),
             sum(rownames(res.complete[[x]]) %in% rownames(res.filled[[x]]))))
}), row.names = c("complete", "filled", "ratio",
                  "filled.in.complete", "complete.in.filled")))

stats
@

\section{Closing words}
This package was developed to analyse (label-free) quantitative MS data, however 
it can be used to analyse any data set with missing values. It was designed
for a flexibel use and its focus is on the biological interpretation of the 
results. 

We are interested in improving the package and making
the analysis of mass spectrometry data sets easy and especially well documented
and not "black-boxy". Please send comments, feedback, and suggestions,
or maybe a thanks to \texttt{schwarzl@embl.de}.

Thank you very much for using \Rpackage{limmas}.

\subsection{Acknowledgement}
Special thanks to Alex von Kriegsheim and David Gomez with providing mass spec knowledge
and experimental data as well as Ente Tiger.
\end{document}
